{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "add_info_to_trajectory.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPkUJnXycZl/34ltzIhRuBe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LironSimon/Exploring_parameter_relations_from_trajectories/blob/main/add_info_to_trajectory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Issues\n",
        "*   add vt2_in_salt values. **Don't run this notebook before that!**\n",
        "*   Vy min is exctly that! greatly effected by noise\n",
        "*   **fix csv 0001_1_1/2 in 0602_batch_1 before running**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y-uSffWKP5ne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import environment and setup"
      ],
      "metadata": {
        "id": "gq-cU7CYQbtm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKp3ewX6yHZa"
      },
      "outputs": [],
      "source": [
        "# Import the necessary packages\n",
        "import glob\n",
        "import pandas as pd\n",
        "import sys \n",
        "# from scipy.optimize import least_squares\n",
        "import numpy as np\n",
        "from sympy import symbols, solve"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount to drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92p4zB14yZro",
        "outputId": "e8473042-5ada-4b07-d357-1c94a066226f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set paths\n",
        "general_path = '/content/gdrive/Shareddrives/Liron_Simon_Thesis/Experimental_data/Trajectories'\n",
        "notebook_path = f'{general_path}/experimental_notebook_summary.csv'\n",
        "joint_data_path = f'{general_path}/joint_trajectory_data.csv'"
      ],
      "metadata": {
        "id": "3SQ8uXgXydcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls /content/gdrive/Shareddrives/Liron_Simon_Thesis/Experimental_data/Trajectories"
      ],
      "metadata": {
        "id": "5mExnT9rzIme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set avg terminal velocity in salt water, as collected from experiment\n",
        "# keys - rho2 density [gr/cm3], values - terminal veocity [m/s]\n",
        "vt2_in_salt = {1.04: float(\"nan\"), \n",
        "               1.05: float(\"nan\"), \n",
        "               1.06: float(\"nan\"), \n",
        "               1.07: float(\"nan\"), \n",
        "               1.08: float(\"nan\"), \n",
        "               1.09: float(\"nan\"), \n",
        "               1.10: float(\"nan\"), \n",
        "               1.11: float(\"nan\"), \n",
        "               1.12: float(\"nan\")}"
      ],
      "metadata": {
        "id": "-R51w7asOFM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write helpfull funcs for calculating data"
      ],
      "metadata": {
        "id": "OdFbVMvxNc9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) finding terminal velocity acourding to trajectory"
      ],
      "metadata": {
        "id": "dKxWiCFF7Cb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vt_from_data(V, pixels, layer, percent=0.10, num_of_frames=10):\n",
        "    '''Takes a column of Vy values, coresponding pixel column, percent of change, and num of frames to avg. \n",
        "    Parameter 'layer' takes an indicator 1 or 2, that states whther to find values in the beginning or ending of the trajectory\n",
        "    Returns: 1) the index at which V has change by over a defined percent from the avg of the first num_of_frames.\n",
        "             2) the pixel detected.\n",
        "             3) the avg value of the velocity up until that index.'''\n",
        "    V = V.dropna()\n",
        "\n",
        "    # if bottom layer is chosen, change order of columns\n",
        "    if layer is 2: \n",
        "        V = V.iloc[::-1]\n",
        "        pixels = pixels.iloc[::-1]\n",
        "\n",
        "    # cut initial nan value that's in index 0\n",
        "    else: V = V[1:]\n",
        "    \n",
        "    # create a list of indices of V deviations\n",
        "    indices = []\n",
        "\n",
        "    init = V[:num_of_frames].mean()\n",
        "    for i,v in enumerate(V):\n",
        "        if init*(1-percent) < v < init*(1+percent): continue\n",
        "        \n",
        "        else: \n",
        "            # ignore a single point if its alot diff from prior frame\n",
        "            if i>0 and V[i-1]*0.5> v or v > V[i-1]*1.5: \n",
        "                indices.append(i)\n",
        "                continue\n",
        "            \n",
        "            # change to real index if layer=2\n",
        "            if layer is 2: \n",
        "                i = len(V)-i\n",
        "                indices = [len(V)-j for j in indices]\n",
        "\n",
        "            # calc mean up until i without deviations\n",
        "            V = V.drop(indices)\n",
        "            mean = V[:i].mean()\n",
        "\n",
        "            return i, round(pixels.loc[i]), mean"
      ],
      "metadata": {
        "id": "hcPnLRklNln6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Finding terminal velocity acourding to given parameters"
      ],
      "metadata": {
        "id": "OFxcjGA17K-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Cd(Re):\n",
        "    #if Re <= 0: Re = 1e-3   \n",
        "    return 0.4 + 24.0/Re + 6.0/(1+Re**0.5)\n",
        "\n",
        "def Vp(d): return np.pi*d**3/6\n",
        "def Ap(d): return np.pi*d**2/4\n",
        "\n",
        "def terminal_velocity(rhop=2500, rhof=1000 , g=9.81, d=1e-3, nu=1e-6):\n",
        "    \"\"\" Inputs:\n",
        "          rhop : particle density, (kg/m^3)\n",
        "          rhof : fluid density, (kg/m^3)\n",
        "          g : gravity acceleration, default = 9.81 ( m/s^2 )\n",
        "          d : particle diameter, (m)\n",
        "          nu : kinematic viscosity, (m^2/s), water is 1e-6   \n",
        "    Outputs:\n",
        "          sol : terminal velocity of the particle (m/s)\n",
        "    \"\"\"\n",
        "    V = symbols('V')\n",
        "    eq = (rhop-rhof)*Vp(d)*g - 0.5*Cd(V*d/nu)*rhof*Ap(d)*(V**2)\n",
        "    sol = solve(eq)\n",
        "\n",
        "    if len(sol)!=1: raise ValueError('more/less than one result for Vt')\n",
        "\n",
        "    return sol[0]"
      ],
      "metadata": {
        "id": "2d3EzkZoYIrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Getting diameter from observed terminal velocity in upper layer"
      ],
      "metadata": {
        "id": "rufVCoZi7fgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def diam_from_terminal_velocity(vt=0.145, rhop=2500, rhof=1000, g=9.81, nu=1e-6):\n",
        "    \"\"\" Inputs:\n",
        "          vt1 : observed terminal velocity in upper fluid layer, (m/s)\n",
        "          rhop : particle density, (kg/m^3)\n",
        "          rhof : fluid density, (kg/m^3)\n",
        "          g : gravity acceleration, default = 9.81 ( m/s^2 )\n",
        "          nu : kinematic viscosity, (m^2/s), water is 1e-6   \n",
        "    Outputs:\n",
        "          d : diam (m)\n",
        "    \"\"\"\n",
        "    d =  symbols('d')\n",
        "    eq = (rhop-rhof)*Vp(d)*g - 0.5*Cd(vt*d/nu)*rhof*Ap(d)*(vt**2)\n",
        "    sol = solve(eq)\n",
        "\n",
        "    if len(sol)!=1: raise ValueError('more than one result for Vt')\n",
        "\n",
        "    # make sure d is within manufacture's range\n",
        "    # if 1e-3 > sol[0] or sol[0] > 1.18e-3: raise ValueError('d is not compatible to range.')\n",
        "\n",
        "    return sol[0]"
      ],
      "metadata": {
        "id": "gKIlJTTa9N6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Calc interface thickness by enty and exit y pixel"
      ],
      "metadata": {
        "id": "pbWjI-LcRWZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def h_in_meters(entry_pt, Batch_id, pixel2m= 0.088/1024):\n",
        "      ####!!!!! Should change this to load from saved csv with all info if we decide to use laser pics\n",
        "      # create a df with laser exit points\n",
        "      df = pd.DataFrame(data=[429,417,404,416], index = [1,2,3,4])\n",
        "\n",
        "      exit_pxl = int(df.loc[Batch_id])\n",
        "\n",
        "      return (exit_pxl - entry_pt)*pixel2m, exit_pxl"
      ],
      "metadata": {
        "id": "hWgUFdUKReGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) reduce size of a df by storing vectors as a list in a single cell"
      ],
      "metadata": {
        "id": "DaHq16x1Efpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def columns2cells(df):\n",
        "    for column in df.columns:\n",
        "        if len(df[column].unique()) > 2:\n",
        "            df[column] = df[column].astype('object')\n",
        "            df.at[0,column] = df[column].tolist()\n",
        "    return df.loc[0,:]"
      ],
      "metadata": {
        "id": "vGrVxgtfDMqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load csv's and add data to them\n",
        "Also saves all csvs in a joint file for easier future analisys"
      ],
      "metadata": {
        "id": "964ilramNiVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "get data from experimental notebook"
      ],
      "metadata": {
        "id": "sWTgmmTxZCPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "notebook = pd.read_csv(notebook_path)"
      ],
      "metadata": {
        "id": "lWDTUxX2ZFL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loop over individual csv's and add data to them"
      ],
      "metadata": {
        "id": "4AgUyPMlZFxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(notebook)):\n",
        "    # extract data relevant to all csv's in the batch\n",
        "    batch_id, rho_particle, rho_up, rho_down, density_ratio, fps, res, temp = notebook.iloc[i,1:-1]\n",
        "    nu_up, nu_down = 1e-6, 1e-6\n",
        "    date = notebook.at[i, 'date'][1:]\n",
        "\n",
        "    # figure out which folder the data is relevent for\n",
        "    folder_name = f'{date}_batch_{batch_id}'\n",
        "\n",
        "    # make sure we have such a folder before we try and open it\n",
        "    if folder_name not in ['0602_batch_1','0602_batch_2','0602_batch_3','0602_batch_4']: continue\n",
        "\n",
        "    # loop over csvs in that folder, add info to them and load them to a joint file\n",
        "    for csv_path in glob.iglob(f'{general_path}/{folder_name}/*'):\n",
        "        df = pd.read_csv(csv_path)\n",
        "\n",
        "        # delete unnecery columns that may apear\n",
        "        if 'Unnamed: 0' in df.columns: df.pop('Unnamed: 0')\n",
        "\n",
        "        # make sure this csv wan't updated before\n",
        "        if len(df.columns) > 7 : continue\n",
        "\n",
        "        # add/rewrite time tracking that starts from 0\n",
        "        df['sec'] = [i/fps for i in range(len(df))]\n",
        "\n",
        "        # add cells of info taken from notebook\n",
        "        df.at[0,['rho_particle', 'rho_up', 'rho_down', 'density_ratio','nu_up','nu_down', 'fps', 'temp']] = rho_particle, rho_up, rho_down, density_ratio, nu_up, nu_down, fps, temp\n",
        "\n",
        "        # use funcs to find Vt1 (up) and Vt2 (down) from velocity vector\n",
        "        indx1, entry_y, Vt1 = vt_from_data(df.Vy,df.y,1)\n",
        "        indx2, entr_y2, Vt2 = vt_from_data(df.Vy,df.y,2)\n",
        "\n",
        "        # add cells with relevent parameter:\n",
        "        df.at[0,['Vt1_observed','Vt2_observed']] = Vt1, Vt2                # terminal velocity in lower/upper layer\n",
        "        d = diam_from_terminal_velocity(vt=Vt1, rhof=rho_up)               # particle diameter corresponding to the observes Vt1. Supposed to be in range of 1-1.18mm\n",
        "        df.at[0,'d'] = d\n",
        "        df.at[0,'Vt1_expected'] = terminal_velocity(rhof=rho_up,d=d)       # expected terminal velocity in upper layer given d\n",
        "        df.at[0,'Vt2_expected'] = terminal_velocity(rhof=rho_down,d=d)     # expected terminal velocity in lower layer given d\n",
        "        df.at[0,'Vt2_avg_from_exp'] = vt2_in_salt[round(rho_down/1000,2)]  # expected terminal velocity in lower layer given fluid density\n",
        "        \n",
        "        # calc and add Re values - 1: up, 2: down\n",
        "        df.at[0,'Re1'], df.at[0,'Re2'] = Vt1*d/nu_up, Vt2*d/nu_down        # Reynolds number in upper/lower layer\n",
        "\n",
        "        # calc and add Fr values - 1: up, 2: down\n",
        "        h, exit_y = h_in_meters(entry_pt=entry_y, Batch_id=batch_id, pixel2m = res)\n",
        "        N  = (2*9.81*(rho_down - rho_up)/h/(rho_up + rho_down))**0.5       # buoyancy frequency   [1/s]\n",
        "        df.at[0,['Fr1','Fr2']] = [Vt1/(N*d), Vt2/(N*d)]                    # Froude number in upper/lower layer\n",
        "\n",
        "        # get index of exit_Y\n",
        "        indx3 = df.y.iloc[(df.y-exit_y).abs().argsort()[:1]].index.values[0]\n",
        "\n",
        "        # get average velocity in interface\n",
        "        df.at[0,'Vavg_in_h'] = df.loc[indx1:indx3,'Vy'].mean()\n",
        "\n",
        "        # get tau recovery time - time from first change in velocity to reaching vt2\n",
        "        df.at[0,'tau_recovery'] = df.loc[indx2, 'sec'] - df.loc[indx1, 'sec']\n",
        "\n",
        "        ###### ??? SHOULD I GET MIN VALUE WITH GREATER CARE? ??? ########\n",
        "        df.at[0,'Vy_min'] =  df.Vy.dropna().min()\n",
        "\n",
        "        # get average velocity in the tau range\n",
        "        df.at[0,'Vavg_in_tau'] = df.loc[indx1:indx2,'Vy'].mean() \n",
        "\n",
        "        # save updated df to drive\n",
        "        df.to_csv(csv_path)\n",
        "\n",
        "        ### save to a joint dataset\n",
        "        # add identification\n",
        "        df.at[0,['date','batch','file_id']] = date, batch_id, csv_path[-12:-4] \n",
        "        # turn df to a row\n",
        "        df = columns2cells(df)                                                 \n",
        "        df.to_csv(joint_data_path, mode='a')"
      ],
      "metadata": {
        "id": "IZiZKr10BQO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "show last csv that was saved"
      ],
      "metadata": {
        "id": "L3dFkw89QTbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(csv_path)"
      ],
      "metadata": {
        "id": "6RisKFXUagI6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}